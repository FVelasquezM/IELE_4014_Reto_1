{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IELE_4014**  \n",
    "**Felipe Velásquez Montoya**   \n",
    "&nbsp;&nbsp;&nbsp;&nbsp; *c.c:* 1018506038   \n",
    "&nbsp;&nbsp;&nbsp;&nbsp; *cód estudiante:* 201632422\n",
    "# Reto 1\n",
    "Problema de clasificación de Pulsares utilizando el dataset HTRU2 (https://archive.ics.uci.edu/ml/datasets/HTRU2) y scikit learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Paso 0**   \n",
    "Instalación de dependencia sklearn (para modelos) y numpy (para matrices y funciones mateḿaticas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in /home/felipe/.local/lib/python3.7/site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in /home/felipe/anaconda3/lib/python3.7/site-packages (from sklearn) (0.20.3)\n",
      "Requirement already satisfied: scipy>=0.13.3 in /home/felipe/anaconda3/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.2.1)\n",
      "Requirement already satisfied: numpy>=1.8.2 in /home/felipe/anaconda3/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.16.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: numpy in /home/felipe/anaconda3/lib/python3.7/site-packages (1.16.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --user sklearn\n",
    "%pip install --user numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Primera parte: Carga y preparación de datos**   \n",
    "Se inicia importando librerías y módulos de sklearn necesarios para realizar el ejercicio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, se cargan los datos de su correspondiente csv. Como se puede comprobar, los datos cargados tienen 17898 filas y 9 columnas, las primeras 8 corresponden al vector X y la última a la clase (y) que se busca predecir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filas de la matriz: 17898\n",
      "Columnas de la matriz: 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "17898"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_matrix = np.loadtxt(open(\"./HTRU2/HTRU_2.csv\", \"rb\"), delimiter=\",\", skiprows=0)\n",
    "\n",
    "print(\"Filas de la matriz: \" + str(len(data_matrix)))\n",
    "print(\"Columnas de la matriz: \" + str(len(data_matrix[0])))\n",
    "\n",
    "X = np.resize(data_matrix, (len(data_matrix), len(data_matrix[0])-1))\n",
    "y = data_matrix[:,8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se utiliza la función train_test_split de sklearn para realizar la separación de datos de entrenamiento y datos de prueba. Como indica el enunciado del reto, 10000 datos son reservados para prueba y los restantes son utilizados para entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño X entrenamiento: 7898 | Tamaño y entrenamiento: 7898\n",
      "Tamaño X prueba: 10000 | Tamaño y prueba: 10000\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 10000.00/float(len(X))) \n",
    "\n",
    "print(\"Tamaño X entrenamiento: %s | Tamaño y entrenamiento: %s\" % (len(X_train), len(y_train)))\n",
    "print(\"Tamaño X prueba: %s | Tamaño y prueba: %s\" % (len(X_test), len(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, los datos reservados para el entrenamiento se parten de nuevo en grupos de 5000, 1000, 500 y 100 elementos elegidos aleatoriamente de los conjuntos *X_train* y *y_train* originales. Para esto, se vuelve a utilizar la función se sklear *train_test_split*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "Set de entrenamiento 0\n",
      "    Tamaño X de entrenamiento: 100 | Tamaño y de entrenamiento: 100\n",
      "-----------------------------\n",
      "Set de entrenamiento 1\n",
      "    Tamaño X de entrenamiento: 500 | Tamaño y de entrenamiento: 500\n",
      "-----------------------------\n",
      "Set de entrenamiento 2\n",
      "    Tamaño X de entrenamiento: 1000 | Tamaño y de entrenamiento: 1000\n",
      "-----------------------------\n",
      "Set de entrenamiento 3\n",
      "    Tamaño X de entrenamiento: 5000 | Tamaño y de entrenamiento: 5000\n"
     ]
    }
   ],
   "source": [
    "sizes = [100.00, 500.00, 1000.00, 5000.00]\n",
    "X_train_array = []\n",
    "y_train_array = []\n",
    "\n",
    "for i in sizes:\n",
    "    Xy = train_test_split(X_train, y_train, test_size = 1.00 - i/float(len(X_train)))\n",
    "    X_train_array.append(Xy[0])\n",
    "    y_train_array.append(Xy[2])\n",
    "    \n",
    "#Verificar tamaños de los nuevos sets de entrenamiento\n",
    "for i in range(0, len(X_train_array)):\n",
    "    print(\"-----------------------------\")\n",
    "    print(\"Set de entrenamiento %s\" % i)\n",
    "    print(\"    Tamaño X de entrenamiento: %s | Tamaño y de entrenamiento: %s\" \n",
    "          % (len(X_train_array[i]), len(y_train_array[i])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, se entrenan 4 modelos de regresión logística utilizando los distintos conjuntos de entrenamiento. **TODO, revisar documentación de solvers y escoger el adecuado** **TODO, explicar mejor este paso**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El Modelo entrenado con 100.0 datos predijo correctamente el 0.9021 porciento de los datos de entrenamiento\n",
      "El Modelo entrenado con 500.0 datos predijo correctamente el 0.9087 porciento de los datos de entrenamiento\n",
      "El Modelo entrenado con 1000.0 datos predijo correctamente el 0.9087 porciento de los datos de entrenamiento\n",
      "El Modelo entrenado con 5000.0 datos predijo correctamente el 0.9087 porciento de los datos de entrenamiento\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9087"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(solver=\"lbfgs\").fit(X_train, y_train)\n",
    "\n",
    "logreg_array = []\n",
    "logreg_score = []\n",
    "best_model_ind = -1\n",
    "best_score = 0.0\n",
    "\n",
    "for i in range(0, len(X_train_array)):\n",
    "    #Se entrena la regresión logística con el conjunto de entrenamiento correspondiente.\n",
    "    logreg_array.append(LogisticRegression(solver=\"lbfgs\").fit(X_train_array[i], y_train_array[i]))\n",
    "    \n",
    "    #Se prueba la regresión logística con los conjuntos de prueba:\n",
    "    logreg_score.append(logreg_array[i].score(X_test, y_test))\n",
    "    \n",
    "    #Se imprimen los resultados del modelo\n",
    "    \n",
    "    print(\"El Modelo entrenado con %s datos predijo correctamente el %s porciento de los datos de entrenamiento\" \n",
    "         % (sizes[i], logreg_score[i]))\n",
    "    \n",
    "    if logreg_score[i] > best_score:\n",
    "        best_mode_indl = i\n",
    "        best_score = logreg_score[i]\n",
    "        \n",
    "best_model = logreg_array[i]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** dar más información de los modelos, tal vez pesos de los parámetros y eso? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
